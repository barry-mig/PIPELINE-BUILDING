# ===================================================================
# PRODUCTION CONFIGURATION FOR ML PIPELINE API
# ===================================================================
# This file contains all configuration settings for deploying the
# Customer Churn Prediction API in production environments.
# 
# Usage:
# 1. Copy this file to .env in your project root
# 2. Modify values according to your environment
# 3. Never commit .env files to version control
# ===================================================================

# ===================================================================
# APPLICATION SETTINGS
# ===================================================================

# Basic application configuration
APP_NAME=Customer Churn Prediction API
APP_VERSION=2.0.0
APP_DESCRIPTION=Production-ready ML API for customer churn prediction
APP_DEBUG=false

# Server configuration
HOST=0.0.0.0
PORT=8001
WORKERS=4
RELOAD=false
LOG_LEVEL=info

# Environment (development, staging, production)
ENVIRONMENT=production
SECRET_KEY=your-super-secret-key-change-this-in-production

# ===================================================================
# DATABASE CONFIGURATION
# ===================================================================

# Primary database for customer data
# PostgreSQL example:
DATABASE_URL=postgresql://username:password@localhost:5432/customer_churn_db
DATABASE_POOL_SIZE=20
DATABASE_MAX_OVERFLOW=10
DATABASE_ECHO=false

# Alternative database examples:
# MySQL: mysql://username:password@localhost:3306/customer_churn_db
# SQLite: sqlite:///./customer_churn.db

# Redis for caching and session management
REDIS_URL=redis://localhost:6379/0
REDIS_PASSWORD=your-redis-password
REDIS_MAX_CONNECTIONS=50

# MongoDB for document storage (optional)
MONGODB_URL=mongodb://localhost:27017/customer_churn
MONGODB_USERNAME=mongodb_user
MONGODB_PASSWORD=mongodb_password

# ===================================================================
# MACHINE LEARNING MODEL CONFIGURATION
# ===================================================================

# Model storage location
MODEL_STORAGE_PATH=/app/models
MODEL_REGISTRY_PATH=/app/models/registry.json

# Active model configuration
DEFAULT_MODEL_VERSION=v2.1.3
MODEL_WARM_UP_ENABLED=true
MODEL_CACHE_SIZE=3

# Model serving configuration
PREDICTION_TIMEOUT_SECONDS=30
BATCH_SIZE_LIMIT=1000
CONCURRENT_PREDICTIONS_LIMIT=100

# Model performance thresholds
MIN_MODEL_ACCURACY=0.80
MODEL_DRIFT_THRESHOLD=0.05
PREDICTION_CONFIDENCE_THRESHOLD=0.60

# ===================================================================
# API SECURITY CONFIGURATION
# ===================================================================

# Authentication
JWT_SECRET_KEY=your-jwt-secret-key-change-this
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=24

# API Keys
API_KEY_HEADER_NAME=X-API-Key
REQUIRE_API_KEY=true

# CORS settings
CORS_ORIGINS=["https://yourcompany.com", "https://app.yourcompany.com"]
CORS_ALLOW_CREDENTIALS=true
CORS_ALLOW_METHODS=["GET", "POST"]
CORS_ALLOW_HEADERS=["Authorization", "Content-Type", "X-API-Key"]

# Trusted hosts
TRUSTED_HOSTS=["api.yourcompany.com", "*.yourcompany.com", "localhost"]

# Rate limiting
RATE_LIMIT_REQUESTS_PER_MINUTE=1000
RATE_LIMIT_BURST_SIZE=100
BATCH_RATE_LIMIT_PER_MINUTE=10

# ===================================================================
# MONITORING AND OBSERVABILITY
# ===================================================================

# Prometheus metrics
PROMETHEUS_ENABLED=true
PROMETHEUS_PORT=9090
PROMETHEUS_ENDPOINT=/metrics

# Logging configuration
LOG_FORMAT=json
LOG_FILE_PATH=/var/log/ml-api/application.log
LOG_MAX_SIZE_MB=100
LOG_BACKUP_COUNT=5

# Health check configuration
HEALTH_CHECK_INTERVAL_SECONDS=30
HEALTH_CHECK_TIMEOUT_SECONDS=5

# External monitoring
DATADOG_ENABLED=false
DATADOG_API_KEY=your-datadog-api-key
SENTRY_ENABLED=false
SENTRY_DSN=your-sentry-dsn

# ===================================================================
# EXTERNAL SERVICES
# ===================================================================

# Email service for notifications
SMTP_HOST=smtp.yourcompany.com
SMTP_PORT=587
SMTP_USERNAME=noreply@yourcompany.com
SMTP_PASSWORD=smtp-password
SMTP_USE_TLS=true

# Webhook configuration
WEBHOOK_TIMEOUT_SECONDS=30
WEBHOOK_RETRY_ATTEMPTS=3
WEBHOOK_RETRY_DELAY_SECONDS=5

# Cloud storage (for model artifacts)
AWS_ACCESS_KEY_ID=your-aws-access-key
AWS_SECRET_ACCESS_KEY=your-aws-secret-key
AWS_S3_BUCKET=your-ml-models-bucket
AWS_REGION=us-west-2

# ===================================================================
# PERFORMANCE TUNING
# ===================================================================

# Request handling
MAX_REQUEST_SIZE_MB=10
REQUEST_TIMEOUT_SECONDS=60
KEEP_ALIVE_TIMEOUT_SECONDS=5

# Connection pooling
DB_CONNECTION_POOL_SIZE=20
REDIS_CONNECTION_POOL_SIZE=50
HTTP_CLIENT_TIMEOUT_SECONDS=30

# Memory management
MAX_MEMORY_USAGE_PERCENT=80
GARBAGE_COLLECTION_THRESHOLD=700

# Caching
CACHE_TTL_SECONDS=3600
CACHE_MAX_SIZE_MB=512
PREDICTION_CACHE_ENABLED=true

# ===================================================================
# BUSINESS CONFIGURATION
# ===================================================================

# Churn prediction thresholds
LOW_RISK_THRESHOLD=0.3
MEDIUM_RISK_THRESHOLD=0.6
HIGH_RISK_THRESHOLD=0.8

# Business rules
ENABLE_RETENTION_RECOMMENDATIONS=true
ENABLE_AUTOMATIC_ALERTS=true
MINIMUM_CUSTOMER_TENURE_DAYS=30

# Notification settings
ALERT_EMAIL_RECIPIENTS=["ml-team@yourcompany.com", "business-team@yourcompany.com"]
CRITICAL_RISK_ALERT_THRESHOLD=0.9
BATCH_COMPLETION_NOTIFICATIONS=true

# ===================================================================
# DATA PROCESSING CONFIGURATION
# ===================================================================

# Data validation
STRICT_VALIDATION_MODE=true
ALLOW_MISSING_OPTIONAL_FIELDS=true
DATA_QUALITY_THRESHOLD=0.80

# Data ingestion
MAX_BATCH_SIZE=1000
CONCURRENT_BATCH_PROCESSING=5
DATA_RETENTION_DAYS=365

# Feature engineering
ENABLE_FEATURE_SCALING=true
ENABLE_FEATURE_SELECTION=false
FEATURE_IMPORTANCE_LOGGING=true

# ===================================================================
# DEPLOYMENT CONFIGURATION
# ===================================================================

# Container settings
CONTAINER_MEMORY_LIMIT=4Gi
CONTAINER_CPU_LIMIT=2000m
CONTAINER_CPU_REQUEST=1000m
CONTAINER_MEMORY_REQUEST=2Gi

# Kubernetes settings
REPLICAS=3
MAX_REPLICAS=10
MIN_REPLICAS=2
CPU_UTILIZATION_THRESHOLD=70

# Load balancer settings
ENABLE_LOAD_BALANCING=true
HEALTH_CHECK_PATH=/health
READINESS_PROBE_PATH=/health
LIVENESS_PROBE_PATH=/health

# ===================================================================
# BACKUP AND DISASTER RECOVERY
# ===================================================================

# Database backups
ENABLE_AUTOMATED_BACKUPS=true
BACKUP_SCHEDULE=0 2 * * *
BACKUP_RETENTION_DAYS=30
BACKUP_STORAGE_LOCATION=s3://your-backup-bucket/ml-api

# Model versioning
MODEL_BACKUP_ENABLED=true
MODEL_VERSION_RETENTION_COUNT=5
MODEL_ROLLBACK_ENABLED=true

# ===================================================================
# DEVELOPMENT AND TESTING
# ===================================================================

# Development settings (only for non-production)
ENABLE_API_DOCS=true
ENABLE_SWAGGER_UI=true
ENABLE_REDOC=true
ENABLE_DEBUG_ENDPOINTS=false

# Testing configuration
TEST_DATABASE_URL=postgresql://test_user:test_pass@localhost:5432/test_db
ENABLE_TEST_MODE=false
MOCK_EXTERNAL_SERVICES=false

# ===================================================================
# FEATURE FLAGS
# ===================================================================

# Experimental features
ENABLE_A_B_TESTING=true
ENABLE_CANARY_DEPLOYMENTS=true
ENABLE_SHADOW_PREDICTIONS=false

# API features
ENABLE_BATCH_PREDICTIONS=true
ENABLE_REAL_TIME_PREDICTIONS=true
ENABLE_MODEL_MANAGEMENT=true
ENABLE_METRICS_EXPORT=true

# Advanced features
ENABLE_AUTO_SCALING=true
ENABLE_CIRCUIT_BREAKER=true
ENABLE_REQUEST_DEDUPLICATION=false

# ===================================================================
# COMPLIANCE AND GOVERNANCE
# ===================================================================

# Data privacy
ENABLE_PII_MASKING=true
DATA_ANONYMIZATION_ENABLED=true
GDPR_COMPLIANCE_MODE=true

# Audit logging
ENABLE_AUDIT_LOGGING=true
AUDIT_LOG_RETENTION_DAYS=2555  # 7 years
LOG_SENSITIVE_DATA=false

# Model governance
MODEL_APPROVAL_REQUIRED=true
ENABLE_MODEL_EXPLAINABILITY=true
BIAS_DETECTION_ENABLED=true

# ===================================================================
# ALERTS AND NOTIFICATIONS
# ===================================================================

# Performance alerts
RESPONSE_TIME_ALERT_THRESHOLD_MS=1000
ERROR_RATE_ALERT_THRESHOLD_PERCENT=5
CPU_USAGE_ALERT_THRESHOLD_PERCENT=80
MEMORY_USAGE_ALERT_THRESHOLD_PERCENT=85

# Business alerts
MODEL_ACCURACY_ALERT_THRESHOLD=0.75
HIGH_CHURN_RATE_ALERT_THRESHOLD=0.20
BATCH_PROCESSING_FAILURE_ALERT=true

# System alerts
DISK_USAGE_ALERT_THRESHOLD_PERCENT=90
DATABASE_CONNECTION_FAILURE_ALERT=true
EXTERNAL_SERVICE_FAILURE_ALERT=true

# ===================================================================
# SAMPLE CONFIGURATION FOR DIFFERENT ENVIRONMENTS
# ===================================================================

# For local development, create .env.local:
# ENVIRONMENT=development
# APP_DEBUG=true
# DATABASE_URL=sqlite:///./dev.db
# LOG_LEVEL=debug
# RELOAD=true

# For staging, create .env.staging:
# ENVIRONMENT=staging
# DATABASE_URL=postgresql://staging_user:staging_pass@staging-db:5432/staging_db
# REPLICAS=2
# LOG_LEVEL=info

# For production, create .env.production:
# ENVIRONMENT=production
# DATABASE_URL=postgresql://prod_user:prod_pass@prod-db:5432/prod_db
# REPLICAS=5
# LOG_LEVEL=warning
# ENABLE_API_DOCS=false

# ===================================================================
# USAGE INSTRUCTIONS
# ===================================================================

# 1. INSTALLATION:
#    Copy this file to .env in your project root
#    Modify values according to your environment

# 2. LOAD CONFIGURATION:
#    pip install python-dotenv
#    from dotenv import load_dotenv
#    load_dotenv()

# 3. ACCESS IN CODE:
#    import os
#    database_url = os.getenv('DATABASE_URL')

# 4. DOCKER COMPOSE:
#    env_file:
#      - .env.production

# 5. KUBERNETES:
#    Create ConfigMap and Secret resources
#    Mount as environment variables

# ===================================================================
# SECURITY NOTES
# ===================================================================

# ðŸ”’ NEVER commit .env files to version control
# ðŸ”’ Use different .env files for different environments
# ðŸ”’ Store sensitive values in secret management systems
# ðŸ”’ Rotate secrets regularly
# ðŸ”’ Use strong, unique passwords and keys
# ðŸ”’ Enable encryption in transit and at rest
# ðŸ”’ Regularly audit access and permissions
# ðŸ”’ Monitor for security vulnerabilities

# ===================================================================
# PERFORMANCE OPTIMIZATION NOTES
# ===================================================================

# ðŸš€ Adjust WORKERS based on CPU cores (2 * cores + 1)
# ðŸš€ Tune database connection pools based on load
# ðŸš€ Enable caching for frequently accessed data
# ðŸš€ Use CDN for static assets
# ðŸš€ Implement request compression
# ðŸš€ Optimize database queries
# ðŸš€ Monitor and optimize memory usage
# ðŸš€ Use async/await for I/O operations
